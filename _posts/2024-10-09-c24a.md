---
title: Speeding up NAS with Adaptive Subset Selection
openreview: hRqiQ2i5ps
abstract: A majority of recent developments in neural architecture search (NAS) have
  been aimed at decreasing the computational cost of various techniques without affecting
  their final performance. Towards this goal, several low-fidelity and performance
  prediction methods have been considered, including those that train only on subsets
  of the training data. In this work, we present an adaptive subset selection approach
  to NAS and present it as complementary to state-of-the-art NAS approaches. We uncover
  a natural connection between one-shot NAS algorithms and adaptive subset selection
  and devise an algorithm that makes use of state-of-the-art techniques from both
  areas. We use these techniques to substantially reduce the runtime of DARTS-PT (a
  leading one-shot NAS algorithm), as well as BOHB and DEHB (leading multi-fidelity
  optimization algorithms), with minimal sacrifice to accuracy. In experiments, we
  find architectures on CIFAR-10 that give 5% increase in performance over DARTS-PT
  while reducing the time required by more than 8 times. Our results are consistent
  across multiple datasets, and towards full reproducibility, we release all our code
  at \url{https://anonymous.4open.science/r/SubsetSelection_NAS-87B3}.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: c24a
month: 0
tex_title: Speeding up NAS with Adaptive Subset Selection
firstpage: 3/1
lastpage: 23
page: 3/1-23
order: 3
cycles: false
bibtex_author: C, Vishak Prasad and White, Colin and Nayak, Sibasis and Jain, Paarth
  and Shameem, Aziz and Garg, Prateek and Ramakrishnan, Ganesh
author:
- given: Vishak Prasad
  family: C
- given: Colin
  family: White
- given: Sibasis
  family: Nayak
- given: Paarth
  family: Jain
- given: Aziz
  family: Shameem
- given: Prateek
  family: Garg
- given: Ganesh
  family: Ramakrishnan
date: 2024-10-09
address:
container-title: Proceedings of the Third International Conference on Automated Machine
  Learning
volume: '256'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 10
  - 9
pdf: https://raw.githubusercontent.com/mlresearch/v256/main/assets/c24a/c24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
