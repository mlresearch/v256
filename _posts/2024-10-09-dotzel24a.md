---
title: 'FLIQS: One-Shot Mixed-Precision Floating-Point and Integer Quantization Search'
openreview: d69NqU8YmM
abstract: Quantization has become a mainstream compression technique for reducing
  model size, computational requirements, and energy consumption for modern deep neural
  networks (DNNs).  With improved numerical support in recent hardware, including
  multiple variants of integer and floating point, mixed-precision quantization has
  become necessary to achieve high-quality results with low model cost.  Prior mixed-precision
  methods have performed either a post-training quantization search, which compromises
  on accuracy, or a differentiable quantization search, which leads to high memory
  usage from branching. Therefore, we propose the first one-shot mixed-precision quantization
  search that eliminates the need for retraining in both integer and low-precision
  floating point models. We evaluate our search (FLIQS) on multiple convolutional
  and vision transformer networks to discover Pareto-optimal models. Our approach
  improves upon uniform precision, manual mixed-precision, and recent integer quantization
  search methods.  With integer models, we increase the accuracy of ResNet-18 on ImageNet
  by 1.3% points and ResNet-50 by 0.90% points with equivalent model cost over previous
  methods. Additionally, for the first time, we explore a novel mixed-precision floating-point
  search and improve MobileNetV2 by up to 0.98% points compared to prior state-of-the-art
  FP8 models. Finally, we extend FLIQS to simultaneously search a joint quantization
  and neural architecture space and improve the ImageNet accuracy by 2.69% points
  with similar model cost on a MobileNetV2 search space.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: dotzel24a
month: 0
tex_title: 'FLIQS: One-Shot Mixed-Precision Floating-Point and Integer Quantization
  Search'
firstpage: 6/1
lastpage: 26
page: 6/1-26
order: 6
cycles: false
bibtex_author: Dotzel, Jordan and Wu, Gang and Li, Andrew and Umar, Muhammad and Ni,
  Yun and Abdelfattah, Mohamed S and Zhang, Zhiru and Cheng, Liqun and Dixon, Martin
  G and Jouppi, Norman P and Le, Quoc V and Li, Sheng
author:
- given: Jordan
  family: Dotzel
- given: Gang
  family: Wu
- given: Andrew
  family: Li
- given: Muhammad
  family: Umar
- given: Yun
  family: Ni
- given: Mohamed S
  family: Abdelfattah
- given: Zhiru
  family: Zhang
- given: Liqun
  family: Cheng
- given: Martin G
  family: Dixon
- given: Norman P
  family: Jouppi
- given: Quoc V
  family: Le
- given: Sheng
  family: Li
date: 2024-10-09
address:
container-title: Proceedings of the Third International Conference on Automated Machine
  Learning
volume: '256'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 10
  - 9
pdf: https://raw.githubusercontent.com/mlresearch/v256/main/assets/dotzel24a/dotzel24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
