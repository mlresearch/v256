---
title: Fast Benchmarking of Asynchronous Multi-Fidelity Optimization on Zero-Cost
  Benchmarks
openreview: uisnH6jUDz
abstract: While deep learning has celebrated many successes, its results often hinge
  on the meticulous selection of hyperparameters (HPs). However, the time-consuming
  nature of deep learning training makes HP optimization (HPO) a costly endeavor,
  slowing down the development of efficient HPO tools. While zero-cost benchmarks,
  which provide performance and runtime without actual training, offer a solution
  for non-parallel setups, they fall short in parallel setups as each worker must
  communicate its queried runtime to return its evaluation in the exact order. This
  work addresses this challenge by introducing a user-friendly Python package that
  facilitates efficient parallel HPO with zero-cost benchmarks. Our approach calculates
  the exact return order based on the information stored in file system, eliminating
  the need for long waiting times and enabling much faster HPO evaluations. We first
  verify the correctness of our approach through extensive testing and the experiments
  with 6 popular HPO libraries show its applicability to diverse libraries and its
  ability to achieve over 1000$\times$ speedup compared to a traditional approach.
  Our package can be installed via pip install mfhpo-simulator.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: watanabe24a
month: 0
tex_title: Fast Benchmarking of Asynchronous Multi-Fidelity Optimization on Zero-Cost
  Benchmarks
firstpage: 14/1
lastpage: 18
page: 14/1-18
order: 14
cycles: false
bibtex_author: Watanabe, Shuhei and Mallik, Neeratyoy and Bergman, Edward and Hutter,
  Frank
author:
- given: Shuhei
  family: Watanabe
- given: Neeratyoy
  family: Mallik
- given: Edward
  family: Bergman
- given: Frank
  family: Hutter
date: 2024-10-09
address:
container-title: Proceedings of the Third International Conference on Automated Machine
  Learning
volume: '256'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 10
  - 9
pdf: https://raw.githubusercontent.com/mlresearch/v256/main/assets/watanabe24a/watanabe24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
