---
title: 'HPOD: Hyperparameter Optimization for Unsupervised Outlier Detection'
openreview: pypP5uaHxg
abstract: Given an unsupervised outlier detection (OD) algorithm, how can we optimize
  its hyperparameter(s) (HP) on a new dataset, without using any labels? In this work,
  we address this challenging hyperparameter optimization for unsupervised OD problem,
  and propose the first continuous HP search method called HPOD. It capitalizes on
  the prior performance of a large collection of HPs on existing OD benchmark datasets,
  and transfers this information to enable HP evaluation on a new dataset without
  labels. Also, HPOD adapts a prominent, (originally) supervised, sampling paradigm
  to efficiently identify promising HPs in iterations. Extensive experiments show
  that HPOD works for both deep (e.g., Robust AutoEncoder (RAE)) and shallow (e.g.,
  Local Outlier Factor (LOF) and Isolation Forest (Forest)) algorithms on discrete
  and continuous HP spaces. HPOD outperforms a wide range of diverse baselines with
  37% improvement on average over the minimal loss HPs of RAE, and 58% and 66% improvement
  on average over the default HPs of LOF and iForest.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhao24a
month: 0
tex_title: 'HPOD: Hyperparameter Optimization for Unsupervised Outlier Detection'
firstpage: 2/1
lastpage: 24
page: 2/1-24
order: 2
cycles: false
bibtex_author: Zhao, Yue and Akoglu, Leman
author:
- given: Yue
  family: Zhao
- given: Leman
  family: Akoglu
date: 2024-10-09
address:
container-title: Proceedings of the Third International Conference on Automated Machine
  Learning
volume: '256'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 10
  - 9
pdf: https://raw.githubusercontent.com/mlresearch/v256/main/assets/zhao24a/zhao24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
